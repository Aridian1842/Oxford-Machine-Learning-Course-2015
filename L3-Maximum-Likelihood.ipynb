{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目标\n",
    "\n",
    "- 高斯分布\n",
    "- 正确表达线性回归的似然率（likelihood）\n",
    "- 计算线性回归的最大似然估计（MLE）\n",
    "- 熵（Entropy）与损失的关系，概率与学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单变量高斯分布\n",
    "\n",
    "高斯分布的概率密度函数（probability density function, PDF）：\n",
    "\n",
    "$$ p(x) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}}e^{-\\frac{1}{2\\sigma^2}(x - \\mu)^2}$$\n",
    "\n",
    "即：\n",
    "\n",
    "$$x \\sim N(\\mu, \\sigma^2)$$\n",
    "\n",
    "其中 $\\mu$ 是均值，$\\sigma^2$ 是方差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 协方差、相关与多元高斯分布\n",
    "\n",
    "> 协方差表示的是两个变量的总体的误差，这与只表示一个变量误差的方差不同。 如果两个变量的变化趋势一致，也就是说如果其中一个大于自身的期望值，另外一个也大于自身的期望值，那么两个变量之间的协方差就是正值。 如果两个变量的变化趋势相反，即其中一个大于自身的期望值，另外一个却小于自身的期望值，那么两个变量之间的协方差就是负值。 [Wikipedia::协方差](https://zh.wikipedia.org/wiki/协方差)\n",
    "\n",
    "$$cov[X, Y] \\equiv E[(X - E[X])(Y - E[Y])] = E[XY] - E[X]E[Y]$$\n",
    "\n",
    "$$E[X] = \\int x p(x) dx = \\mu \\approx \\frac{1}{N}\\sum_{i=1}^N x_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**协方差矩阵**\n",
    "\n",
    "假设$\\mathbf{X}$是$n$个随机变数组成的列向量：\n",
    "\n",
    "$$ \\mathbf{X} = \\begin{bmatrix}X_1\\\\\\vdots\\\\X_n\\end{bmatrix}$$\n",
    "\n",
    "且 $\\mu_i$ 是其第 $i$ 个变数的期望值，即 $\\mu_i = E(X_i)$，协方差矩阵的第$i, j$项定义为：\n",
    "\n",
    "$\\sum_{ij} = cov(X_i, X_j) = E[(X_i - \\mu_i)(X_j - u_j)]$\n",
    "\n",
    "协方差矩阵为：\n",
    "\n",
    "$$\\sum = E[(X - E[X])(X - E[X])^T] = \\begin{bmatrix}var[X_1] & cov[X_1, X_2] & \\dots & cov[X_1, X_n] \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ cov[X_d, X_1] & cov[X_d, X_2] & \\dots & var[X_n]\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二元高斯分布\n",
    "\n",
    "两独立高斯分布变量 $x_1 = N(\\mu_1, \\sigma^2)$，$x_2 = N(\\mu_2, \\sigma^2)$，其联合概率分布$p(x_1, x_2)$：\n",
    "\n",
    "![L3-1](imgs/L3-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**数学推导**\n",
    "\n",
    "$$let \\sum = \\begin{bmatrix} \\sigma^2 & 0 \\\\ 0 & \\sigma^2 \\end{bmatrix},$$\n",
    "\n",
    "$$\\left|\\sum\\right| = (\\sigma^2)^2,$$\n",
    "\n",
    "$$\\left|a\\sum\\right| = a^2\\left|\\sum\\right|$$\n",
    "\n",
    "$$p(x_1 x_2) = p(x_1)p(x_2) \\\\ = \\frac{1}{\\sqrt{2\\pi \\sigma^2}}e^{-\\frac{1}{2\\sigma^2}(x_1 - \\mu)^2}\\frac{1}{\\sqrt{2\\pi \\sigma^2}}e^{-\\frac{1}{2\\sigma^2}(x_2 - \\mu)^2}\\\\= \\left|2\\pi\\sum\\right|^{-1/2}e^{-1/2[X-\\mu]^T\\sum^{-1}[X-\\mu]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLE 实例\n",
    "\n",
    "假设有 $n = 3$ 个数据点，$y_1 = 1, y_2 = 0.5, y_3 = 1.5$，属于参数为 $N(\\theta, 1)$ 的独立高斯分布：\n",
    "\n",
    "$$y_i \\sim N(\\theta, 1)$$\n",
    "\n",
    "则得到这3个数据的似然率为：$p(y_1y_2y_3|\\theta) = p(y_1|\\theta)p(y_2|\\theta)p(y_3|\\theta)$，考虑两种猜测，$\\theta = 1, \\theta = 2.5$，哪个更可能？\n",
    "\n",
    "![L3-2](imgs/L3-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线性回归的似然率\n",
    "\n",
    "假设线性回归中每个 $y_i = N(x_i^T\\theta, \\sigma^2) = x_i^T\\theta + N(0, \\sigma^2)$，则：\n",
    "\n",
    "$$p(\\mathbf{y}|\\mathbf{X, \\theta), \\sigma} = \\prod_{i=1}^n p(y_i|x_i, \\theta, \\sigma) \\\\ = \\prod_{i=1}^n (2\\pi\\sigma^2)^{-1/2}e^{-\\frac{1}{2\\sigma^2}(y_i-x_i^T\\theta)^2} \\\\ = (2\\pi\\sigma^2)^{-n/2}e^{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n(y_i-x_i^T\\theta)^2} \\\\ = (2\\pi\\sigma^2)^{-n/2}e^{-\\frac{1}{2\\sigma^2}(\\mathbf{y} - \\mathbf{X\\theta})^T(\\mathbf{y} - \\mathbf{X\\theta})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "损失函数：\n",
    "\n",
    "$$J(\\theta) = \\sum_{i=1}^n(y_i - x_i^T\\theta)^2$$\n",
    "\n",
    "假设，\n",
    "\n",
    "$$\\hat{y}(x_i) = \\theta_1 + x_i\\theta_2$$\n",
    "\n",
    "$$J(\\theta) = \\sum_{i=1}^n(y_i - \\theta_1 - x_i\\theta_2)^2$$\n",
    "\n",
    "怎样取 $\\theta_1, \\theta_2$ 可以使损失函数最小化？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最大似然率\n",
    "\n",
    "最大似然率估计（MLE）对线性回归似然率取对数：$log p(y|X,\\theta, \\sigma)$\n",
    "\n",
    "![L3-3](imgs/L3-3.png)\n",
    "\n",
    "即$(\\mathbf{y} - \\mathbf{X\\theta})^T(\\mathbf{y} - \\mathbf{X\\theta})$ 最小化。\n",
    "\n",
    "对 $\\theta$ 的最大估计为 $\\frac{\\partial}{\\partial \\theta} \\frac{1}{2\\sigma^2} (\\mathbf{y} - \\mathbf{X\\theta})$\n",
    "\n",
    "$$\\Theta_{ML} = (X^TX)^{-1}X^TY$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 熵\n",
    "\n",
    "信息论中，熵H用于衡量随机变量的不确定性：\n",
    "\n",
    "$$H(X) = \\sum_x p(x|\\theta) log p(x|\\theta)$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
